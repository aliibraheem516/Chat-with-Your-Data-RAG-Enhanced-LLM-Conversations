{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Cell 1: Install Required Libraries"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AsmSyKO1NvLU"
      },
      "outputs": [],
      "source": [
        "!pip install faiss-cpu\n",
        "!pip install fitz\n",
        "!pip install PyMuPDF\n",
        "!pip install transformers"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Cell 2: Extract Text from PDF"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AQiDua1ARpZ4",
        "outputId": "6d89c86d-0a17-45e0-c8ff-28925cb0a9bf"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Text extracted successfully!\n"
          ]
        }
      ],
      "source": [
        "import fitz  # PyMuPDF\n",
        "\n",
        "def extract_text_from_pdf(pdf_path):\n",
        "    doc = fitz.open(pdf_path)\n",
        "    text = \"\"\n",
        "    for page in doc:\n",
        "        text += page.get_text()\n",
        "    return text\n",
        "\n",
        "# Replace with the path to your PDF\n",
        "pdf_path = \"Hands-On_Machine_Learning.pdf\"\n",
        "book_text = extract_text_from_pdf(pdf_path)\n",
        "\n",
        "print(\"Text extracted successfully!\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Cell 3: Clean and Preprocess Text"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2pz8yTaGSMQO",
        "outputId": "71abaaa9-c370-498a-b1af-aaf24f68b82a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Text cleaned successfully!\n"
          ]
        }
      ],
      "source": [
        "import re\n",
        "\n",
        "def clean_text(text):\n",
        "    # Remove extra spaces and newlines\n",
        "    text = re.sub(r'\\s+', ' ', text)\n",
        "    # Remove special characters (optional)\n",
        "    text = re.sub(r'[^\\x00-\\x7F]+', ' ', text)\n",
        "    return text.strip()\n",
        "\n",
        "book_text = clean_text(book_text)\n",
        "print(\"Text cleaned successfully!\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Cell 4: Split Text into Chunks"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nyU7gGHrSRxa",
        "outputId": "848a7ee0-4218-43da-f18f-7571cbcdf374"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Text split into 1338 chunks.\n"
          ]
        }
      ],
      "source": [
        "def split_into_chunks(text, words_per_chunk=200):\n",
        "    words = text.split()\n",
        "    chunks = [' '.join(words[i:i + words_per_chunk]) for i in range(0, len(words), words_per_chunk)]\n",
        "    return chunks\n",
        "\n",
        "chunks = split_into_chunks(book_text, words_per_chunk=200)\n",
        "print(f\"Text split into {len(chunks)} chunks.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Cell 5: Generate Embeddings for Chunks"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ygMEUfvmShxP",
        "outputId": "54590daa-df84-430a-c1d6-ad738d2369d9"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Generated embeddings for 1338 chunks.\n"
          ]
        }
      ],
      "source": [
        "from sentence_transformers import SentenceTransformer\n",
        "\n",
        "# Load the embedding model\n",
        "embedding_model = SentenceTransformer('all-MiniLM-L6-v2')\n",
        "\n",
        "# Generate embeddings for the chunks\n",
        "chunk_embeddings = embedding_model.encode(chunks)\n",
        "\n",
        "print(f\"Generated embeddings for {len(chunks)} chunks.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Cell 6: Build FAISS Index for Retrieval"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZyRMuP-0TPIc",
        "outputId": "b398a154-a3db-480a-ab47-92673cd6b6c5"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "FAISS index built successfully!\n"
          ]
        }
      ],
      "source": [
        "import faiss\n",
        "import numpy as np\n",
        "\n",
        "# Convert embeddings to a numpy array\n",
        "chunk_embeddings = np.array(chunk_embeddings).astype('float32')\n",
        "\n",
        "# Build the FAISS index\n",
        "dimension = chunk_embeddings.shape[1]  # Dimension of the embeddings\n",
        "index = faiss.IndexFlatL2(dimension)   # L2 distance for similarity search\n",
        "index.add(chunk_embeddings)            # Add embeddings to the index\n",
        "\n",
        "print(\"FAISS index built successfully!\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Cell 7: Retrieve Relevant Chunks"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "x9gvZZMqTZDJ"
      },
      "outputs": [],
      "source": [
        "def retrieve_relevant_chunks(question, top_k=3):\n",
        "    # Generate embedding for the question\n",
        "    question_embedding = embedding_model.encode([question])\n",
        "    question_embedding = np.array(question_embedding).astype('float32')\n",
        "\n",
        "    # Search the FAISS index\n",
        "    distances, indices = index.search(question_embedding, top_k)\n",
        "    relevant_chunks = [chunks[i] for i in indices[0]]\n",
        "    return relevant_chunks\n",
        "\n",
        "# Test the retrieval system\n",
        "question = \"What is the difference between supervised and unsupervised learning?\"\n",
        "relevant_chunks = retrieve_relevant_chunks(question)\n",
        "print(\"Relevant chunks:\")\n",
        "for i, chunk in enumerate(relevant_chunks):\n",
        "    print(f\"\\nChunk {i + 1}:\\n{chunk}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Cell 8: Load Generative Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PjDCTnUkUU0T"
      },
      "outputs": [],
      "source": [
        "from transformers import pipeline\n",
        "\n",
        "# Load the generative model (flan-t5-small)\n",
        "generator = pipeline(\"text2text-generation\", model=\"Qwen/Qwen2.5-1.5B-Instruct\")\n",
        "\n",
        "# Test the generative model\n",
        "test_output = generator(\"Translate English to French: How are you?\")\n",
        "print(test_output)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Cell 9: Generate Answers"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Gz_3WGrnUdd6"
      },
      "outputs": [],
      "source": [
        "def generate_answer(question, relevant_chunks):\n",
        "    # Combine the relevant chunks into a single context\n",
        "    context = \"\\n\".join(relevant_chunks)\n",
        "\n",
        "    # Create a prompt for the generative model\n",
        "    prompt = f\"Answer the following question based on the context:\\n\\nContext: {context}\\n\\nQuestion: {question}\\nAnswer:\"\n",
        "\n",
        "    # Generate the answer\n",
        "    answer = generator(prompt, max_length=1000, num_return_sequences=1)\n",
        "    return answer[0]['generated_text']\n",
        "\n",
        "# Test the generative model with a question and relevant chunks\n",
        "question = \"What is the difference between supervised and unsupervised learning?\"\n",
        "answer = generate_answer(question, relevant_chunks)\n",
        "print(f\"Answer: {answer}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Cell 10: Test Generative Model with Another Question"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "R8BKI0dcsEL0"
      },
      "outputs": [],
      "source": [
        "# Test the generative model with a question and relevant chunks\n",
        "question = \"what is the knn and what is the cost function of it?\"\n",
        "answer = generate_answer(question, relevant_chunks)\n",
        "print(f\"Answer: {answer}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Cell 11: Full RAG Pipeline"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lAJgZ9j0Uhzr"
      },
      "outputs": [],
      "source": [
        "def rag_pipeline(question, top_k=3):\n",
        "    # Step 1: Retrieve relevant chunks\n",
        "    relevant_chunks = retrieve_relevant_chunks(question, top_k)\n",
        "\n",
        "    # Step 2: Generate an answer using the generative model\n",
        "    answer = generate_answer(question, relevant_chunks)\n",
        "    return answer\n",
        "\n",
        "# Test the full RAG pipeline\n",
        "question = \"what is the cost function of knn \"\n",
        "answer = rag_pipeline(question)\n",
        "print(f\"Answer: {answer}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Cell 12: Test RAG Pipeline with Multiple Questions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6E0JIDqrUoLz"
      },
      "outputs": [],
      "source": [
        "questions = [\n",
        "    \"What is overfitting in machine learning?\",\n",
        "    \"How does gradient descent work?\",\n",
        "    \"What is the purpose of a validation set?\"\n",
        "]\n",
        "\n",
        "for q in questions:\n",
        "    answer = rag_pipeline(q)\n",
        "    print(f\"Question: {q}\")\n",
        "    print(f\"Answer: {answer}\\n\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Cell 13: Save FAISS Index and Chunks"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OxwKPXwiWe6c",
        "outputId": "d225a1bc-18d4-4276-99d1-eb8ccceaee55"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "FAISS index and chunks saved successfully!\n"
          ]
        }
      ],
      "source": [
        "import pickle\n",
        "\n",
        "# Save the FAISS index\n",
        "faiss.write_index(index, \"book_index.faiss\")\n",
        "\n",
        "# Save the chunks\n",
        "with open(\"book_chunks.pkl\", \"wb\") as f:\n",
        "    pickle.dump(chunks, f)\n",
        "\n",
        "print(\"FAISS index and chunks saved successfully!\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Cell 14: Load FAISS Index and Chunks"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "824nJ-b6WkYS",
        "outputId": "f2f89c81-0250-4c65-bb37-666fd048ab1a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "FAISS index and chunks loaded successfully!\n"
          ]
        }
      ],
      "source": [
        "# Load the FAISS index\n",
        "index = faiss.read_index(\"book_index.faiss\")\n",
        "\n",
        "# Load the chunks\n",
        "with open(\"book_chunks.pkl\", \"rb\") as f:\n",
        "    chunks = pickle.load(f)\n",
        "\n",
        "print(\"FAISS index and chunks loaded successfully!\")"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.12"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
